---
title: "Simulating 2020 Using Markets"
output:
  github_document: 
    df_print: tibble
    toc: true
    toc_dept: 2
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  comment = "#>",
  fig.path = "../plots/",
  fig.width = 10,
  dpi = 300
)
options(width = 99)
set.seed(seed = 05)
```

Election prediction helps party officials, campaign operatives, and journalists interpret
campaigns in a quantitative manner. Uncertainty is key to a useful election prediction.

The forecast model has become a staple of political punditry. Popularized by the data journalist
at FiveThirtyEight, the forecasting model is a statistical tool used to incorporate a number of
quantitative inputs and produce a _probabilistic_ view of all possible outcomes.

Prediction markets can be used to generate similarly probabilistic views of election outcomes by
utilizing the economic forces of price discovery and risk aversion to overcome the ideological
bias of self-interested traders on a binary options exchange.

Can we possibly use these prediction markets to generate a useful probabalistic simulation of the
electoral college? We'll try and use data from the PredictIt exchange and R code to answer this
question.


```{r packages, warning=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_current_gh("kiernann/campfin")
pacman::p_load(
  tidyverse,
  jsonlite,
  magrittr,
  janitor,
  rvest,
  usmap
)
```

## Market Data

PredictIt hosts markets for most of the contenious battleground states. We can scrape these
markets using their API and the `jsonlite` package.

```{r scrape_markets}
ec_markets <-
  fromJSON(txt = "https://www.predictit.org/api/marketdata/all/") %>%
  use_series(markets) %>%
  filter(str_detect(name, "Which party will win (.*) in the 2020 presidential election?")) %>%
  unnest(contracts, names_repair = make_clean_names) %>%
  filter(short_name_2 == "Democratic") %>%
  select(state = short_name, price = last_close_price) %>%
  mutate(state = str_extract(state, "[:upper:]{2}")) %>% 
  arrange(price)
```

```{r map_markets, echo=FALSE}
usa_map <- map_data("state") %>% mutate(state = abrev_state(region))
states_ec_map <- left_join(x = usa_map, y = ec_markets)
states_ec_map %>%
  ggplot(mapping = aes(x = long, y = lat, group = group)) +
  geom_polygon(color = "black", mapping = aes(fill = price)) +
  coord_quickmap() +
  scale_fill_distiller(
    type = "div", 
    palette = "RdBu", 
    trans = "reverse",
    labels = scales::dollar
  ) +
  theme(
    legend.position = "none",
    panel.background = element_blank(),
    panel.grid = element_blank(),
    plot.title = element_text(hjust = 0.5),
    axis.text  = element_blank(),
    axis.title = element_blank(),
    axis.ticks = element_blank()
  ) +
  ggtitle("2020 Prediction Markets")
```

## Historical Data

To generate a full probabalistic view of the election, we'll need to calculate probabilities for
those states for which there is not a market. It's incredibly reductive, but I'll use 2016 data
normally distributed with a reasonable standard deviation. To make things simple, we will ignore
Maine and Nebraska's congressional district apportionment.

```{r scrape_past}
past_results <-
  read_html("https://en.wikipedia.org/wiki/2016_United_States_presidential_election") %>%
  html_node("table.wikitable:nth-child(1)") %>%
  html_table(fill = TRUE) %>%
  na_if("â€“") %>%
  as_tibble(.name_repair = "unique") %>%
  select(1, 4, 5, 8) %>%
  slice(-1, -58, -59) %>%
  set_names(c("state", "dem", "dem_votes", "rep_votes")) %>%
  map_dfc(parse_guess) %>% 
  mutate(
    votes = coalesce(dem_votes, rep_votes),
    dem = parse_double(str_remove(dem, "%"))/100,
    state = state %>% 
      str_remove("\\(at-lg\\)") %>% 
      str_remove(",\\s\\d..$") %>% 
      abrev_state()
  ) %>% 
  group_by(state) %>% 
  summarize(
    past = mean(dem),
    votes = sum(votes)
  )
```

```{r 2016_map, echo=FALSE}
states_2016_map <- left_join(x = usa_map, y = past_results)
states_2016_map %>%
  ggplot(mapping = aes(x = long, y = lat, group = group)) +
  geom_polygon(color = "black", mapping = aes(fill = past)) +
  coord_quickmap() +
  scale_fill_distiller(
    type = "div", 
    palette = "RdBu", 
    trans = "reverse",
    labels = scales::dollar
  ) +
  theme(
    legend.position = "none",
    panel.background = element_blank(),
    panel.grid = element_blank(),
    plot.title = element_text(hjust = 0.5),
    axis.text  = element_blank(),
    axis.title = element_blank(),
    axis.ticks = element_blank()
  ) +
  ggtitle("2016 Popular Vote Results")
```

## Probabilities

Any good election forcast needs to be _probabalistic_. Professional forecasts take this division of
votes (usually from an aggrigate of polls) then calculate the probablility distribution around that
range with a series of other factors.

For this simulation, we already have probabilities for `r nrow(ec_markets)` states. PredictIt only
hosts markets for the most contentious states. The reality is the other `r 51-nrow(ec_markets)` 
contests are fairly uncompetitive. From the density plot below, we can see how the range of 
popular vote splits differs for those states with 2020 markets and those without.

```{r vote_range, echo=FALSE}
past_results %>%
  filter(state != "DC") %>%
  mutate(
    market = if_else(
      condition = state %in% ec_markets$state,
      true = "No Market",
      false = "Market Exists"
    )
  ) %>% 
  ggplot(aes(x = past)) + 
  geom_density(aes(fill = market)) +
  facet_wrap(~market, ncol = 1, scales = "free_y") +
  scale_x_continuous(labels = scales::percent) +
  scale_fill_manual(
    guide = FALSE,
    values = c(
      RColorBrewer::brewer.pal(3, "Dark2")[1],
      RColorBrewer::brewer.pal(3, "Dark2")[2]
    )
  ) +
  labs(
    title = "Popular Vote Difference for Battleground States",
    x = "2016 Popular Vote",
    y = "Number of States"
  )
```

To turn the 2016 vote share (e.g., 65%, 48%) into probabilities, we will give each state a standard
deviation of `0.05`. That means we can expect that state to vote similarly to 2016, but give it a
range of possible values on either side. From the density plot of such a simulated distribution,
we can see that a state with a 65% vote in 2016 will win over 50% _most_ of the time. The area of
the curve past 50% is the probability of that win.

```{r example_range, echo=FALSE}
state <- "CT"
past <- past_results$past[past_results$state == state]
ggplot(data = NULL, mapping = aes(x = rnorm(n = 1000, mean = past, sd = 0.05))) + 
  geom_density(fill = RColorBrewer::brewer.pal(3, "Dark2")[3]) +
  geom_vline(xintercept = 0.5) +
  geom_vline(xintercept = past, linetype = 2) +
  scale_x_continuous(labels = scales::percent) +
  labs(
    title = "Example Connecticut Vote Distribution",
    x = "Popular Vote",
    y = "Simulated Occurances"
  ) +
  theme(plot.title = element_text(hjust = 0.50))
```

We can perform such random normal simulations for each of the states without a market to generate
a probability from the 2016 vote. For each state, we generate 100,000 simulate elections and
calculate the percent of those simulated elections where the democrat won.

```{r simulate_elections}
past_results <- mutate(past_results, prob = NA)
for (i in seq_along(past_results$state)) {
  sims <- rnorm(n = 100000, mean = past_results$past[i], sd = 0.10)
  past_results$prob[i] <- mean(sims > 0.5)
}
```

```{r past_results_hist, echo=FALSE}
past_results %>% 
  mutate(dem = past > 0.5) %>% 
  ggplot(aes(x = past)) +
  geom_histogram(bins = 10, mapping = aes(fill = dem)) +
  geom_vline(xintercept = 0.5) +
  labs(
    title = "Popular Vote Distribution",
    x = "Popular Vote",
    y = "2016 States"
  ) +
  scale_x_continuous(labels = scales::percent) +
  scale_fill_manual(
    values = RColorBrewer::brewer.pal(8, "RdBu")[c(1, 8)],
    guide = FALSE
  ) +
  theme(plot.title = element_text(hjust = 0.50))
```

```{r sim_prob_hist, echo=FALSE}
past_results %>% 
  mutate(dem = prob > 0.5) %>% 
  ggplot(aes(x = prob)) +
  geom_histogram(bins = 10, mapping = aes(fill = dem)) +
  geom_vline(xintercept = 0.5) +
  labs(
    title = "Simulated Probability Distribution",
    x = "Popular Vote",
    y = "2016 States"
  ) +
  scale_x_continuous(labels = scales::percent) +
  scale_fill_manual(
    values = RColorBrewer::brewer.pal(8, "RdBu")[c(1, 8)],
    guide = FALSE
  ) +
  theme(plot.title = element_text(hjust = 0.50))
```
